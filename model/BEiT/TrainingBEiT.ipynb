{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim\\AppData\\Local\\Temp/ipykernel_16212/3893446471.py:44: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = datasets.load_metric(\"f1\")\n",
      "Some weights of the model checkpoint at microsoft/beit-base-patch16-224-pt22k were not used when initializing BeitForImageClassification: ['layernorm.weight', 'layernorm.bias', 'lm_head.bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing BeitForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BeitForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BeitForImageClassification were not initialized from the model checkpoint at microsoft/beit-base-patch16-224-pt22k and are newly initialized: ['classifier.weight', 'beit.pooler.layernorm.bias', 'classifier.bias', 'beit.pooler.layernorm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import torch\n",
    "from transformers import BeitForImageClassification, BeitFeatureExtractor, BeitImageProcessor\n",
    "import numpy as np\n",
    "\n",
    "base_model_name = \"microsoft/beit-base-patch16-224-pt22k\"\n",
    "\n",
    "processor = BeitImageProcessor.from_pretrained(base_model_name)\n",
    "\n",
    "def crop_image(img):\n",
    "    width, height = img.size\n",
    "    target_size = min(width, height)\n",
    "    left = max(0, (width - target_size ) // 2)\n",
    "    right = left + target_size\n",
    "    top = max(0, (height - target_size ) // 2)\n",
    "    bottom = top + target_size\n",
    "    return img.crop((left, top, right, bottom)).convert('RGB')\n",
    "\n",
    "def process_example(example):\n",
    "    img = crop_image(example['image'])\n",
    "    inputs = processor(img, return_tensors='pt')\n",
    "    inputs['labels'] = example['label']\n",
    "    return inputs\n",
    "\n",
    "def transform(example_batch):\n",
    "    # Take a list of PIL images and turn them to pixel values\n",
    "    inputs = processor([crop_image(x) for x in example_batch['image']], return_tensors='pt')\n",
    "\n",
    "    # Don't forget to include the labels!\n",
    "    inputs['labels'] = example_batch['label']\n",
    "    return inputs\n",
    "\n",
    "ds = datasets.load_from_disk(\"../../data/diffusion_and_real/\")\n",
    "\n",
    "prepared_ds = ds.with_transform(transform)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['labels'] for x in batch])\n",
    "    }\n",
    "\n",
    "metric = datasets.load_metric(\"f1\")\n",
    "def compute_metrics(p):\n",
    "    return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)\n",
    "\n",
    "labels = [\"negative\",\"positive\"]\n",
    "\n",
    "model = BeitForImageClassification.from_pretrained(\n",
    "    base_model_name,\n",
    "    num_labels=len(labels),\n",
    "    id2label={str(i): c for i, c in enumerate(labels)},\n",
    "    label2id={c: str(i) for i, c in enumerate(labels)}\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"./BEiT-diff-detect\",\n",
    "  per_device_train_batch_size=32, # consider 16 or higher  # add dropout\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=3,\n",
    "  fp16=True,\n",
    "  save_steps=6000,\n",
    "  eval_steps=48,\n",
    "  logging_steps=1125,\n",
    "  learning_rate=2e-4,\n",
    "  save_total_limit=3,\n",
    "  logging_first_step=True,\n",
    "  remove_unused_columns=False,\n",
    "  push_to_hub=False,\n",
    "  report_to='tensorboard',\n",
    "  load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=prepared_ds[\"train\"],\n",
    "    eval_dataset=prepared_ds[\"vali\"],\n",
    "    tokenizer=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tim\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 1/1689 [00:10<4:59:14, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7526, 'learning_rate': 0.0002, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "  3%|▎         | 48/1689 [04:54<1:40:33,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.501287043094635, 'eval_f1': 0.7867768595041322, 'eval_runtime': 111.669, 'eval_samples_per_second': 8.955, 'eval_steps_per_second': 1.119, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  6%|▌         | 96/1689 [06:43<23:04,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.45942792296409607, 'eval_f1': 0.731527093596059, 'eval_runtime': 14.4836, 'eval_samples_per_second': 69.044, 'eval_steps_per_second': 8.63, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "  9%|▊         | 144/1689 [07:39<22:18,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6004758477210999, 'eval_f1': 0.768503937007874, 'eval_runtime': 13.7722, 'eval_samples_per_second': 72.61, 'eval_steps_per_second': 9.076, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 11%|█▏        | 192/1689 [08:41<23:20,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.293561190366745, 'eval_f1': 0.8773784355179703, 'eval_runtime': 16.0256, 'eval_samples_per_second': 62.4, 'eval_steps_per_second': 7.8, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 14%|█▍        | 240/1689 [09:32<19:29,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3103949725627899, 'eval_f1': 0.8644444444444445, 'eval_runtime': 13.1537, 'eval_samples_per_second': 76.024, 'eval_steps_per_second': 9.503, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 17%|█▋        | 288/1689 [10:26<22:37,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2314113825559616, 'eval_f1': 0.903353057199211, 'eval_runtime': 13.9609, 'eval_samples_per_second': 71.629, 'eval_steps_per_second': 8.954, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 20%|█▉        | 336/1689 [11:12<17:34,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23260511457920074, 'eval_f1': 0.904950495049505, 'eval_runtime': 10.3047, 'eval_samples_per_second': 97.043, 'eval_steps_per_second': 12.13, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 23%|██▎       | 384/1689 [11:50<15:19,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.39369526505470276, 'eval_f1': 0.8210526315789474, 'eval_runtime': 13.155, 'eval_samples_per_second': 76.017, 'eval_steps_per_second': 9.502, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 26%|██▌       | 432/1689 [14:35<48:02,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20550310611724854, 'eval_f1': 0.9147609147609148, 'eval_runtime': 45.6928, 'eval_samples_per_second': 21.885, 'eval_steps_per_second': 2.736, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 28%|██▊       | 480/1689 [15:55<14:03,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3017582893371582, 'eval_f1': 0.8367816091954022, 'eval_runtime': 22.6976, 'eval_samples_per_second': 44.057, 'eval_steps_per_second': 5.507, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 31%|███▏      | 528/1689 [17:08<15:01,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19784249365329742, 'eval_f1': 0.9271653543307087, 'eval_runtime': 12.076, 'eval_samples_per_second': 82.809, 'eval_steps_per_second': 10.351, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 34%|███▍      | 576/1689 [18:32<13:24,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17989766597747803, 'eval_f1': 0.9368104312938816, 'eval_runtime': 49.8486, 'eval_samples_per_second': 20.061, 'eval_steps_per_second': 2.508, 'epoch': 1.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 37%|███▋      | 624/1689 [19:18<12:35,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23422278463840485, 'eval_f1': 0.895424836601307, 'eval_runtime': 11.6376, 'eval_samples_per_second': 85.928, 'eval_steps_per_second': 10.741, 'epoch': 1.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 40%|███▉      | 672/1689 [20:03<11:50,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22150222957134247, 'eval_f1': 0.9256360078277887, 'eval_runtime': 11.4494, 'eval_samples_per_second': 87.341, 'eval_steps_per_second': 10.918, 'epoch': 1.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 43%|████▎     | 720/1689 [20:48<11:39,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22654065489768982, 'eval_f1': 0.9051724137931034, 'eval_runtime': 11.6176, 'eval_samples_per_second': 86.076, 'eval_steps_per_second': 10.76, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 45%|████▌     | 768/1689 [21:37<10:35,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1583857387304306, 'eval_f1': 0.9389389389389389, 'eval_runtime': 15.3861, 'eval_samples_per_second': 64.994, 'eval_steps_per_second': 8.124, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 48%|████▊     | 816/1689 [22:26<11:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22388193011283875, 'eval_f1': 0.921487603305785, 'eval_runtime': 14.1559, 'eval_samples_per_second': 70.642, 'eval_steps_per_second': 8.83, 'epoch': 1.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 51%|█████     | 864/1689 [23:14<10:20,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1805724799633026, 'eval_f1': 0.9282868525896415, 'eval_runtime': 11.7527, 'eval_samples_per_second': 85.087, 'eval_steps_per_second': 10.636, 'epoch': 1.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 54%|█████▍    | 912/1689 [24:00<09:31,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22186490893363953, 'eval_f1': 0.8998899889988998, 'eval_runtime': 11.5055, 'eval_samples_per_second': 86.915, 'eval_steps_per_second': 10.864, 'epoch': 1.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 57%|█████▋    | 960/1689 [24:46<08:49,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15720757842063904, 'eval_f1': 0.9466263846928499, 'eval_runtime': 11.3153, 'eval_samples_per_second': 88.376, 'eval_steps_per_second': 11.047, 'epoch': 1.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 60%|█████▉    | 1008/1689 [25:31<08:01,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15362103283405304, 'eval_f1': 0.9457523029682703, 'eval_runtime': 11.6626, 'eval_samples_per_second': 85.744, 'eval_steps_per_second': 10.718, 'epoch': 1.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 63%|██████▎   | 1056/1689 [26:16<07:22,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15603256225585938, 'eval_f1': 0.9403714565004888, 'eval_runtime': 11.4304, 'eval_samples_per_second': 87.486, 'eval_steps_per_second': 10.936, 'epoch': 1.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 65%|██████▌   | 1104/1689 [27:02<06:58,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13539032638072968, 'eval_f1': 0.9567901234567902, 'eval_runtime': 11.6426, 'eval_samples_per_second': 85.891, 'eval_steps_per_second': 10.736, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1125/1689 [27:17<06:37,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2638, 'learning_rate': 6.714031971580817e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 68%|██████▊   | 1152/1689 [27:47<06:28,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2028977870941162, 'eval_f1': 0.9402390438247011, 'eval_runtime': 11.4905, 'eval_samples_per_second': 87.029, 'eval_steps_per_second': 10.879, 'epoch': 2.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 71%|███████   | 1200/1689 [28:32<05:36,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.158633291721344, 'eval_f1': 0.9477911646586347, 'eval_runtime': 11.6696, 'eval_samples_per_second': 85.693, 'eval_steps_per_second': 10.712, 'epoch': 2.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 74%|███████▍  | 1248/1689 [29:18<05:06,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16604219377040863, 'eval_f1': 0.9363920750782065, 'eval_runtime': 11.6366, 'eval_samples_per_second': 85.936, 'eval_steps_per_second': 10.742, 'epoch': 2.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 77%|███████▋  | 1296/1689 [30:03<04:39,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16741609573364258, 'eval_f1': 0.946611909650924, 'eval_runtime': 11.5595, 'eval_samples_per_second': 86.509, 'eval_steps_per_second': 10.814, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 80%|███████▉  | 1344/1689 [30:49<04:06,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15039804577827454, 'eval_f1': 0.9566094853683148, 'eval_runtime': 11.5775, 'eval_samples_per_second': 86.374, 'eval_steps_per_second': 10.797, 'epoch': 2.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 82%|████████▏ | 1392/1689 [31:33<03:25,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1896335780620575, 'eval_f1': 0.9386892177589852, 'eval_runtime': 11.4785, 'eval_samples_per_second': 87.12, 'eval_steps_per_second': 10.89, 'epoch': 2.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 85%|████████▌ | 1440/1689 [32:20<03:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1552370935678482, 'eval_f1': 0.9516129032258065, 'eval_runtime': 11.6346, 'eval_samples_per_second': 85.951, 'eval_steps_per_second': 10.744, 'epoch': 2.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 88%|████████▊ | 1488/1689 [33:05<02:21,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17198829352855682, 'eval_f1': 0.9494949494949494, 'eval_runtime': 11.4094, 'eval_samples_per_second': 87.647, 'eval_steps_per_second': 10.956, 'epoch': 2.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 91%|█████████ | 1536/1689 [33:56<02:02,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14362381398677826, 'eval_f1': 0.9596774193548386, 'eval_runtime': 13.3792, 'eval_samples_per_second': 74.743, 'eval_steps_per_second': 9.343, 'epoch': 2.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 94%|█████████▍| 1584/1689 [34:49<01:27,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15035580098628998, 'eval_f1': 0.9530469530469531, 'eval_runtime': 12.9698, 'eval_samples_per_second': 77.102, 'eval_steps_per_second': 9.638, 'epoch': 2.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 97%|█████████▋| 1632/1689 [35:49<00:39,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1516994833946228, 'eval_f1': 0.9538461538461538, 'eval_runtime': 11.9429, 'eval_samples_per_second': 83.732, 'eval_steps_per_second': 10.466, 'epoch': 2.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 99%|█████████▉| 1680/1689 [36:40<00:06,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15105971693992615, 'eval_f1': 0.9538461538461538, 'eval_runtime': 13.9387, 'eval_samples_per_second': 71.743, 'eval_steps_per_second': 8.968, 'epoch': 2.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1689/1689 [36:47<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2207.1281, 'train_samples_per_second': 24.466, 'train_steps_per_second': 0.765, 'train_loss': 0.20243481533847807, 'epoch': 3.0}\n",
      "***** train metrics *****\n",
      "  epoch                    =        3.0\n",
      "  train_loss               =     0.2024\n",
      "  train_runtime            = 0:36:47.12\n",
      "  train_samples_per_second =     24.466\n",
      "  train_steps_per_second   =      0.765\n"
     ]
    }
   ],
   "source": [
    "# start the training\n",
    "train_results = trainer.train()\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:12<00:00, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =        3.0\n",
      "  eval_f1                 =     0.9617\n",
      "  eval_loss               =     0.1135\n",
      "  eval_runtime            = 0:00:12.38\n",
      "  eval_samples_per_second =     80.761\n",
      "  eval_steps_per_second   =     10.095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# eval\n",
    "metrics = trainer.evaluate(prepared_ds['test'])\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
